{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FatSecret API - Food Dataset Collection\n",
        "## Project: Diet Plan App ML Dataset\n",
        "\n",
        "**Tujuan**: Mengumpulkan data makanan dan nutrisi dari FatSecret API untuk training model machine learning\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "okRD-FA7SDdI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krklLIt54uHf",
        "outputId": "5ee81f96-4b78-4464-ed9e-8c084aaf6012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from google.colab import userdata\n",
        "import logging\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CONFIGURATION\n",
        "# ============================================\n",
        "\n",
        "CONFIG = {\n",
        "    # API Credentials\n",
        "    'CLIENT_ID': userdata.get('FATSECRET_CLIENT_ID'),\n",
        "    'CLIENT_SECRET': userdata.get('FATSECRET_CLIENT_SECRET'),\n",
        "\n",
        "    # ===================================\n",
        "    # TARGETED SEARCH KEYWORDS\n",
        "    # ===================================\n",
        "    'KEYWORDS_EXCEL': 'only_food_list_with_en.xlsx',\n",
        "\n",
        "    # ===================================\n",
        "    # SEARCH & FILTERING PARAMETERS\n",
        "    # ===================================\n",
        "    'MAX_RESULTS_PER_PAGE': 20,\n",
        "    'MAX_FOODS_PER_KEYWORD': 20,\n",
        "    'DELAY_BETWEEN_REQUESTS': 0.5,   # seconds (rate limiting)\n",
        "\n",
        "    # Filtering criteria\n",
        "    'FOOD_TYPE_FILTER': 'Generic',   # Only Generic (not Brand)\n",
        "\n",
        "    # ===================================\n",
        "    # OUTPUT SETTINGS\n",
        "    # ===================================\n",
        "    'OUTPUT_FILE': 'fatsecret_raw_data_dump.xlsx',\n",
        "}\n",
        "\n",
        "# ============================================\n",
        "# LOAD KEYWORDS FROM EXCEL\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"LOADING KEYWORDS FROM EXCEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load Excel (kolom: food_name)\n",
        "df_keywords = pd.read_excel(CONFIG['KEYWORDS_EXCEL'])\n",
        "\n",
        "print(f\"Loaded: {CONFIG['KEYWORDS_EXCEL']}\")\n",
        "print(f\"   Total rows: {len(df_keywords)}\")\n",
        "print(f\"   Columns: {list(df_keywords.columns)}\")\n",
        "\n",
        "# Ambil daftar keyword\n",
        "keywords_list = df_keywords['food_name'].tolist()\n",
        "\n",
        "# Bersihkan keyword kosong / NaN\n",
        "keywords_list = [k for k in keywords_list if pd.notna(k) and str(k).strip() != '']\n",
        "\n",
        "print(f\"\\nValid keywords to search: {len(keywords_list)}\")\n",
        "print(f\"   Expected max foods: ~{len(keywords_list) * CONFIG['MAX_FOODS_PER_KEYWORD']}\")\n",
        "print(f\"   Estimated time: ~{len(keywords_list) * CONFIG['DELAY_BETWEEN_REQUESTS'] / 60:.1f} minutes\")\n",
        "\n",
        "print(\"\\n Sample keywords:\")\n",
        "for i, kw in enumerate(keywords_list[:10], 1):\n",
        "    print(f\"   {i}. {kw}\")\n",
        "\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6QUcKehYyCF",
        "outputId": "b8fc96c7-387b-4669-fa21-cb48abf9b538"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "LOADING KEYWORDS FROM EXCEL\n",
            "======================================================================\n",
            "Loaded: only_food_list_with_en.xlsx\n",
            "   Total rows: 70\n",
            "   Columns: ['food_name']\n",
            "\n",
            "Valid keywords to search: 70\n",
            "   Expected max foods: ~1400\n",
            "   Estimated time: ~0.6 minutes\n",
            "\n",
            " Sample keywords:\n",
            "   1. Egg\n",
            "   2. Coffee\n",
            "   3. Tea\n",
            "   4. Soup\n",
            "   5. Ice Cream\n",
            "   6. Pudding\n",
            "   7. Nuggets\n",
            "   8. Curry\n",
            "   9. Potatoes\n",
            "   10. Noodles\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# AUTHENTICATION\n",
        "# ============================================\n",
        "\n",
        "class FatSecretAuth:\n",
        "    \"\"\"Handle FatSecret OAuth 2.0 authentication\"\"\"\n",
        "\n",
        "    def __init__(self, client_id, client_secret):\n",
        "        self.client_id = client_id\n",
        "        self.client_secret = client_secret\n",
        "        self.access_token = None\n",
        "        self.token_expiry = None\n",
        "\n",
        "    def get_access_token(self):\n",
        "        \"\"\"Get new access token\"\"\"\n",
        "        token_url = 'https://oauth.fatsecret.com/connect/token'\n",
        "        auth_data = {\n",
        "            'grant_type': 'client_credentials',\n",
        "            'scope': 'basic'\n",
        "        }\n",
        "\n",
        "        logger.info(\"ðŸ”‘ Requesting access token...\")\n",
        "\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                token_url,\n",
        "                auth=(self.client_id, self.client_secret),\n",
        "                data=auth_data,\n",
        "                timeout=10\n",
        "            )\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                self.access_token = data['access_token']\n",
        "                self.token_expiry = time.time() + data.get('expires_in', 3600)\n",
        "                logger.info(\"Access token obtained!\")\n",
        "                return self.access_token\n",
        "            else:\n",
        "                logger.error(f\"Token request failed: {response.text}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Authentication error: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def get_valid_token(self):\n",
        "        \"\"\"Get valid token (refresh if needed)\"\"\"\n",
        "        if self.access_token is None or self.is_token_expired():\n",
        "            return self.get_access_token()\n",
        "        return self.access_token\n",
        "\n",
        "    def is_token_expired(self):\n",
        "        \"\"\"Check if token expired\"\"\"\n",
        "        if self.token_expiry is None:\n",
        "            return True\n",
        "        return time.time() >= (self.token_expiry - 300)\n",
        "\n",
        "# Initialize\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"AUTHENTICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "auth = FatSecretAuth(CONFIG['CLIENT_ID'], CONFIG['CLIENT_SECRET'])\n",
        "ACCESS_TOKEN = auth.get_access_token()\n",
        "\n",
        "if ACCESS_TOKEN:\n",
        "    print(f\"Authenticated successfully!\")\n",
        "else:\n",
        "    print(\"Authentication failed! Check credentials.\")\n"
      ],
      "metadata": {
        "id": "ZbMAbs8sSu5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a47006ab-778b-482e-8419-84f2474be7b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "AUTHENTICATION\n",
            "======================================================================\n",
            "Authenticated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# API FUNCTIONS\n",
        "# ============================================\n",
        "\n",
        "def search_foods_v1(query, token, max_results=20, page_number=0):\n",
        "    \"\"\"\n",
        "    Search foods using FatSecret API\n",
        "    Returns raw API response\n",
        "    \"\"\"\n",
        "    max_results = min(max(1, max_results), 50)\n",
        "\n",
        "    headers = {'Authorization': f'Bearer {token}'}\n",
        "    url = \"https://platform.fatsecret.com/rest/foods/search/v1\"\n",
        "\n",
        "    params = {\n",
        "        'search_expression': query,\n",
        "        'format': 'json',\n",
        "        'max_results': max_results,\n",
        "        'page_number': page_number\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, params=params, timeout=10)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if 'error' in data:\n",
        "                logger.error(f\"API Error: {data['error']}\")\n",
        "                return None\n",
        "            return data\n",
        "        else:\n",
        "            logger.error(f\"HTTP Error {response.status_code}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "print(\"API functions loaded\")\n"
      ],
      "metadata": {
        "id": "CKwAFvbOS3nM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff7437c-7497-4fe7-c2b8-fc87c9d8f0b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API functions loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# COLLECTION FUNCTION (RAW DATA ONLY)\n",
        "# ============================================\n",
        "\n",
        "def collect_raw_foods_for_keyword(query, token, max_per_page=20, max_foods=10):\n",
        "    \"\"\"\n",
        "    Collect RAW food data (NO preprocessing, NO name prioritization)\n",
        "\n",
        "    - Hanya ambil food_type == 'Generic'\n",
        "    - Ambil sampai max_foods hasil pertama dari API (API sudah urutkan by relevance)\n",
        "    - Return list of dict:\n",
        "      - food_id\n",
        "      - food_name\n",
        "      - food_type\n",
        "      - description\n",
        "      - search_keyword\n",
        "    \"\"\"\n",
        "    logger.info(f\"ðŸ” Searching '{query}'\")\n",
        "\n",
        "    # Search page 0 only\n",
        "    results = search_foods_v1(query, token, max_per_page, page_number=0)\n",
        "\n",
        "    if not results or 'foods' not in results:\n",
        "        logger.warning(\"   No results\")\n",
        "        return []\n",
        "\n",
        "    foods_data = results['foods']\n",
        "    if 'food' not in foods_data:\n",
        "        logger.warning(\"   No food data\")\n",
        "        return []\n",
        "\n",
        "    # Parse foods\n",
        "    foods = foods_data['food']\n",
        "    if isinstance(foods, dict):\n",
        "        foods = [foods]\n",
        "\n",
        "    # Filter: Generic only\n",
        "    generic_foods = [f for f in foods if f.get('food_type') == CONFIG['FOOD_TYPE_FILTER']]\n",
        "\n",
        "    if not generic_foods:\n",
        "        logger.warning(\"   No Generic foods\")\n",
        "        return []\n",
        "\n",
        "    selected_foods = generic_foods[:max_foods]\n",
        "\n",
        "    raw_foods = []\n",
        "\n",
        "    for food in selected_foods:\n",
        "        food_name = food.get('food_name', 'Unknown')\n",
        "        description = food.get('food_description', '')\n",
        "\n",
        "        raw_food = {\n",
        "            'food_id': food.get('food_id'),\n",
        "            'food_name': food_name,\n",
        "            'food_type': food.get('food_type', 'Unknown'),\n",
        "            'description': description,\n",
        "            'search_keyword': query,\n",
        "        }\n",
        "\n",
        "        raw_foods.append(raw_food)\n",
        "        logger.info(f\"   {food_name}\")\n",
        "\n",
        "    logger.info(f\"   Collected {len(raw_foods)} foods for '{query}'\")\n",
        "\n",
        "    return raw_foods\n",
        "\n",
        "print(\"Collection function ready (RAW, Generic-only, no prioritization)\")\n"
      ],
      "metadata": {
        "id": "gsULGfVtS8pg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854e99e6-ae91-4da4-9ff5-64660820da27"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection function ready (RAW, Generic-only, no prioritization)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# EXECUTE COLLECTION\n",
        "# ============================================\n",
        "\n",
        "all_raw_data = []\n",
        "stats = {\n",
        "    'total_keywords': 0,\n",
        "    'successful': 0,\n",
        "    'failed': 0,\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STARTING RAW DATA COLLECTION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for idx, keyword in enumerate(keywords_list, 1):\n",
        "    stats['total_keywords'] += 1\n",
        "\n",
        "    # Get fresh token\n",
        "    token = auth.get_valid_token()\n",
        "\n",
        "    # Collect RAW data\n",
        "    foods = collect_raw_foods_for_keyword(\n",
        "        query=keyword,\n",
        "        token=token,\n",
        "        max_per_page=CONFIG['MAX_RESULTS_PER_PAGE'],\n",
        "        max_foods=CONFIG['MAX_FOODS_PER_KEYWORD']\n",
        "    )\n",
        "\n",
        "    if foods:\n",
        "        all_raw_data.extend(foods)\n",
        "        stats['successful'] += 1\n",
        "    else:\n",
        "        stats['failed'] += 1\n",
        "        print(f\"   {keyword}: No data\")\n",
        "\n",
        "    # Progress log setiap 10 keyword\n",
        "    if idx % 10 == 0:\n",
        "        print(f\"\\n--- Progress: {idx}/{len(keywords_list)} keywords processed ---\")\n",
        "\n",
        "    # Rate limiting\n",
        "    time.sleep(CONFIG['DELAY_BETWEEN_REQUESTS'])\n",
        "\n",
        "# ============================================\n",
        "# DEDUPLICATION\n",
        "# ============================================\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ðŸ§¹ REMOVING DUPLICATES\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "df_temp = pd.DataFrame(all_raw_data)\n",
        "print(f\"Before deduplication: {len(df_temp)} rows\")\n",
        "\n",
        "# Cek duplicate food_id\n",
        "duplicates = df_temp[df_temp.duplicated(subset=['food_id'], keep='first')]\n",
        "if len(duplicates) > 0:\n",
        "    print(f\"\\n Found {len(duplicates)} duplicate food_ids (showing up to 10):\")\n",
        "    for _, dup in duplicates.head(10).iterrows():\n",
        "        print(f\"   â€¢ ID {dup['food_id']:>6}: {dup['food_name']} (keyword: {dup['search_keyword']})\")\n",
        "\n",
        "# Drop duplicates\n",
        "df_temp = df_temp.drop_duplicates(subset=['food_id'], keep='first')\n",
        "\n",
        "print(f\"\\nAfter deduplication: {len(df_temp)} rows\")\n",
        "print(f\"Removed: {len(all_raw_data) - len(df_temp)} duplicate rows\")\n",
        "\n",
        "# Convert back to list of dict\n",
        "all_raw_data = df_temp.to_dict('records')\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"COLLECTION COMPLETE!\")\n",
        "print(f\"{'='*70}\")\n",
        "print(\"Statistics:\")\n",
        "print(f\"   â€¢ Keywords searched : {stats['total_keywords']}\")\n",
        "print(f\"   â€¢ Successful        : {stats['successful']}\")\n",
        "print(f\"   â€¢ Failed            : {stats['failed']}\")\n",
        "print(f\"   â€¢ Total foods final : {len(all_raw_data)}\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "VHhchr42TBDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2635df27-1372-40a5-8798-8da24e90e8c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STARTING RAW DATA COLLECTION\n",
            "======================================================================\n",
            "\n",
            "--- Progress: 10/70 keywords processed ---\n",
            "\n",
            "--- Progress: 20/70 keywords processed ---\n",
            "\n",
            "--- Progress: 30/70 keywords processed ---\n",
            "\n",
            "--- Progress: 40/70 keywords processed ---\n",
            "\n",
            "--- Progress: 50/70 keywords processed ---\n",
            "\n",
            "--- Progress: 60/70 keywords processed ---\n",
            "\n",
            "--- Progress: 70/70 keywords processed ---\n",
            "\n",
            "======================================================================\n",
            "ðŸ§¹ REMOVING DUPLICATES\n",
            "======================================================================\n",
            "Before deduplication: 563 rows\n",
            "\n",
            " Found 16 duplicate food_ids (showing up to 10):\n",
            "   â€¢ ID   5279: Tangerine (keyword: Tangerine)\n",
            "   â€¢ ID  35890: Tangerines (Mandarin Oranges) (keyword: Tangerine)\n",
            "   â€¢ ID   6229: Green String Beans (keyword: Green beans)\n",
            "   â€¢ ID   6314: Cooked Green String Beans (from Fresh) (keyword: Green beans)\n",
            "   â€¢ ID   6370: Cooked Green String Beans (Fat Added in Cooking) (keyword: Green beans)\n",
            "   â€¢ ID   6397: Cooked Green String Beans (from Frozen) (keyword: Green beans)\n",
            "   â€¢ ID   6346: Cooked Green String Beans (from Fresh, Fat Added in Cooking) (keyword: Green beans)\n",
            "   â€¢ ID   6462: Cooked Green String Beans (from Fresh, Fat Not Added in Cooking) (keyword: Green beans)\n",
            "   â€¢ ID   6644: Green String Beans with Onions (Fat Added in Cooking) (keyword: Green beans)\n",
            "   â€¢ ID   6371: Cooked Green String Beans (from Canned, Fat Added in Cooking) (keyword: Green beans)\n",
            "\n",
            "After deduplication: 547 rows\n",
            "Removed: 16 duplicate rows\n",
            "\n",
            "======================================================================\n",
            "COLLECTION COMPLETE!\n",
            "======================================================================\n",
            "Statistics:\n",
            "   â€¢ Keywords searched : 70\n",
            "   â€¢ Successful        : 70\n",
            "   â€¢ Failed            : 0\n",
            "   â€¢ Total foods final : 547\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# SAVE RAW DATA\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAVING RAW DATA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "df_raw = pd.DataFrame(all_raw_data)\n",
        "\n",
        "print(\"\\n Dataset Info:\")\n",
        "print(f\"   Shape  : {df_raw.shape}\")\n",
        "print(f\"   Columns: {list(df_raw.columns)}\")\n",
        "\n",
        "print(\"\\n Sample data (first 5 rows):\")\n",
        "print(df_raw[['food_name', 'food_type', 'search_keyword']].head(5))\n",
        "\n",
        "# Save\n",
        "if CONFIG['OUTPUT_FILE'].lower().endswith('.csv'):\n",
        "    df_raw.to_csv(CONFIG['OUTPUT_FILE'], index=False)\n",
        "else:\n",
        "    df_raw.to_excel(CONFIG['OUTPUT_FILE'], index=False)\n",
        "\n",
        "print(f\"\\n Raw data saved to: {CONFIG['OUTPUT_FILE']}\")\n",
        "print(f\"   Total rows   : {len(df_raw)}\")\n",
        "print(f\"   Total columns: {len(df_raw.columns)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COLLECTION PHASE COMPLETE!\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "ziOcRtXV28y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e935096-51ba-44c6-ca20-1788c9cf22fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ðŸ’¾ SAVING RAW DATA\n",
            "======================================================================\n",
            "\n",
            "ðŸ“Š Dataset Info:\n",
            "   Shape  : (547, 5)\n",
            "   Columns: ['food_id', 'food_name', 'food_type', 'description', 'search_keyword']\n",
            "\n",
            "ðŸ“„ Sample data (first 5 rows):\n",
            "                       food_name food_type search_keyword\n",
            "0                            Egg   Generic            Egg\n",
            "1                      Fried Egg   Generic            Egg\n",
            "2                     Boiled Egg   Generic            Egg\n",
            "3  Scrambled Egg (Whole, Cooked)   Generic            Egg\n",
            "4                      Egg White   Generic            Egg\n",
            "\n",
            "âœ… Raw data saved to: fatsecret_raw_data_dump.csv\n",
            "   Total rows   : 547\n",
            "   Total columns: 5\n",
            "\n",
            "======================================================================\n",
            "ðŸŽ¯ COLLECTION PHASE COMPLETE!\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}